{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2016 - 2019 Pinard Liu(liujianping-ok@163.com)\n",
    "\n",
    "https://www.cnblogs.com/pinard\n",
    "\n",
    "Permission given to modify the code as long as you keep this declaration at the top\n",
    "\n",
    "用scikit-learn学习LDA主题模型 https://www.cnblogs.com/pinard/p/6908150.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import jieba\n",
    "\n",
    "with open('./nlp_test0.txt') as f:\n",
    "    document = f.read()\n",
    "    \n",
    "    document_decode = document.decode('GBK')\n",
    "    document_cut = jieba.cut(document_decode)\n",
    "    #print  ' '.join(jieba_cut)  //如果打印结果，则分词效果消失，后面的result无法显示\n",
    "    result = ' '.join(document_cut)\n",
    "    result = result.encode('utf-8')\n",
    "    with open('./nlp_test1.txt', 'w') as f2:\n",
    "        f2.write(result)\n",
    "f.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq('沙瑞金', True)\n",
    "jieba.suggest_freq('易学习', True)\n",
    "jieba.suggest_freq('王大路', True)\n",
    "jieba.suggest_freq('京州', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./nlp_test0.txt') as f:\n",
    "    document = f.read()\n",
    "    \n",
    "    document_decode = document.decode('GBK')\n",
    "    document_cut = jieba.cut(document_decode)\n",
    "    #print  ' '.join(jieba_cut)\n",
    "    result = ' '.join(document_cut)\n",
    "    result = result.encode('utf-8')\n",
    "    with open('./nlp_test1.txt', 'w') as f2:\n",
    "        f2.write(result)\n",
    "f.close()\n",
    "f2.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从文件导入停用词表\n",
    "stpwrdpath = \"stop_words.txt\"\n",
    "stpwrd_dic = open(stpwrdpath, 'rb')\n",
    "stpwrd_content = stpwrd_dic.read()\n",
    "#将停用词表转换为list  \n",
    "stpwrdlst = stpwrd_content.splitlines()\n",
    "stpwrd_dic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沙瑞金 赞叹 易学习 的 胸怀 ， 是 金山 的 百姓 有福 ， 可是 这件 事对 李达康 的 触动 很大 。 易学习 又 回忆起 他们 三人 分开 的 前一晚 ， 大家 一起 喝酒 话别 ， 易学习 被 降职 到 道口 县当 县长 ， 王大路 下海经商 ， 李达康 连连 赔礼道歉 ， 觉得 对不起 大家 ， 他 最 对不起 的 是 王大路 ， 就 和 易学习 一起 给 王大路 凑 了 5 万块 钱 ， 王大路 自己 东挪西撮 了 5 万块 ， 开始 下海经商 。 没想到 后来 王大路 竟然 做 得 风生水 起 。 沙瑞金 觉得 他们 三人 ， 在 困难 时期 还 能 以沫 相助 ， 很 不 容易 。\n"
     ]
    }
   ],
   "source": [
    "with open('./nlp_test1.txt') as f3:\n",
    "    res1 = f3.read()\n",
    "print res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./nlp_test2.txt') as f:\n",
    "    document2 = f.read()\n",
    "    \n",
    "    document2_decode = document2.decode('GBK')\n",
    "    document2_cut = jieba.cut(document2_decode)\n",
    "    #print  ' '.join(jieba_cut)\n",
    "    result = ' '.join(document2_cut)\n",
    "    result = result.encode('utf-8')\n",
    "    with open('./nlp_test3.txt', 'w') as f2:\n",
    "        f2.write(result)\n",
    "f.close()\n",
    "f2.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沙瑞金 向 毛娅 打听 他们 家 在 京州 的 别墅 ， 毛娅 笑 着 说 ， 王大路 事业有成 之后 ， 要 给 欧阳 菁 和 她 公司 的 股权 ， 她们 没有 要 ， 王大路 就 在 京州 帝豪园 买 了 三套 别墅 ， 可是 李达康 和 易学习 都 不要 ， 这些 房子 都 在 王大路 的 名下 ， 欧阳 菁 好像 去 住 过 ， 毛娅 不想 去 ， 她 觉得 房子 太大 很 浪费 ， 自己 家住 得 就 很 踏实 。\n"
     ]
    }
   ],
   "source": [
    "with open('./nlp_test3.txt') as f4:\n",
    "    res2 = f4.read()\n",
    "print res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.suggest_freq('桓温', True)\n",
    "with open('./nlp_test4.txt') as f:\n",
    "    document3 = f.read()\n",
    "    \n",
    "    document3_decode = document3.decode('GBK')\n",
    "    document3_cut = jieba.cut(document3_decode)\n",
    "    #print  ' '.join(jieba_cut)\n",
    "    result = ' '.join(document3_cut)\n",
    "    result = result.encode('utf-8')\n",
    "    with open('./nlp_test5.txt', 'w') as f3:\n",
    "        f3.write(result)\n",
    "f.close()\n",
    "f3.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347 年 （ 永和 三年 ） 三月 ， 桓温 兵至 彭模 （ 今 四川 彭山 东南 ） ， 留下 参军 周楚 、 孙盛 看守 辎重 ， 自己 亲率 步兵 直攻 成都 。 同月 ， 成汉 将领 李福 袭击 彭模 ， 结果 被 孙盛 等 人 击退 ； 而 桓温 三 战三胜 ， 一直 逼近 成都 。\n"
     ]
    }
   ],
   "source": [
    "with open('./nlp_test5.txt') as f5:\n",
    "    res3 = f5.read()\n",
    "print res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 44)\t0.154467434933\n",
      "  (0, 59)\t0.108549295069\n",
      "  (0, 39)\t0.308934869866\n",
      "  (0, 53)\t0.108549295069\n",
      "  (0, 65)\t0.108549295069\n",
      "  (0, 49)\t0.108549295069\n",
      "  (0, 40)\t0.108549295069\n",
      "  (0, 20)\t0.0772337174664\n",
      "  (0, 62)\t0.108549295069\n",
      "  (0, 10)\t0.108549295069\n",
      "  (0, 41)\t0.154467434933\n",
      "  (0, 56)\t0.108549295069\n",
      "  (0, 35)\t0.108549295069\n",
      "  (0, 24)\t0.108549295069\n",
      "  (0, 12)\t0.154467434933\n",
      "  (0, 2)\t0.217098590137\n",
      "  (0, 15)\t0.108549295069\n",
      "  (0, 17)\t0.108549295069\n",
      "  (0, 26)\t0.217098590137\n",
      "  (0, 0)\t0.217098590137\n",
      "  (0, 23)\t0.108549295069\n",
      "  (0, 57)\t0.108549295069\n",
      "  (0, 66)\t0.108549295069\n",
      "  (0, 64)\t0.108549295069\n",
      "  (0, 18)\t0.108549295069\n",
      "  :\t:\n",
      "  (1, 55)\t0.0995336411066\n",
      "  (1, 54)\t0.0995336411066\n",
      "  (1, 43)\t0.419673178975\n",
      "  (1, 37)\t0.139891059658\n",
      "  (1, 11)\t0.279782119316\n",
      "  (1, 16)\t0.279782119316\n",
      "  (1, 9)\t0.139891059658\n",
      "  (1, 8)\t0.139891059658\n",
      "  (1, 42)\t0.279782119316\n",
      "  (1, 14)\t0.139891059658\n",
      "  (1, 52)\t0.139891059658\n",
      "  (1, 28)\t0.139891059658\n",
      "  (1, 46)\t0.139891059658\n",
      "  (1, 33)\t0.139891059658\n",
      "  (1, 3)\t0.139891059658\n",
      "  (1, 6)\t0.139891059658\n",
      "  (1, 61)\t0.139891059658\n",
      "  (1, 36)\t0.279782119316\n",
      "  (1, 21)\t0.139891059658\n",
      "  (1, 29)\t0.139891059658\n",
      "  (1, 5)\t0.139891059658\n",
      "  (1, 27)\t0.139891059658\n",
      "  (1, 47)\t0.139891059658\n",
      "  (1, 30)\t0.139891059658\n",
      "  (1, 60)\t0.139891059658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [res1,res2]\n",
    "vector = TfidfVectorizer(stop_words=stpwrdlst)\n",
    "tfidf = vector.fit_transform(corpus)\n",
    "print tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------第 0 段文本的词语tf-idf权重------\n",
      "一起 0.217098590137\n",
      "万块 0.217098590137\n",
      "三人 0.217098590137\n",
      "三套 0.0\n",
      "下海经商 0.217098590137\n",
      "不想 0.0\n",
      "不要 0.0\n",
      "东挪西撮 0.108549295069\n",
      "之后 0.0\n",
      "事业有成 0.0\n",
      "事对 0.108549295069\n",
      "京州 0.0\n",
      "他们 0.154467434933\n",
      "以沫 0.108549295069\n",
      "公司 0.0\n",
      "分开 0.108549295069\n",
      "别墅 0.0\n",
      "前一晚 0.108549295069\n",
      "县当 0.108549295069\n",
      "县长 0.108549295069\n",
      "可是 0.0772337174664\n",
      "名下 0.0\n",
      "后来 0.108549295069\n",
      "喝酒 0.108549295069\n",
      "回忆起 0.108549295069\n",
      "困难 0.108549295069\n",
      "大家 0.217098590137\n",
      "太大 0.0\n",
      "她们 0.0\n",
      "好像 0.0\n",
      "家住 0.0\n",
      "容易 0.108549295069\n",
      "对不起 0.217098590137\n",
      "帝豪园 0.0\n",
      "开始 0.108549295069\n",
      "很大 0.108549295069\n",
      "房子 0.0\n",
      "打听 0.0\n",
      "时期 0.108549295069\n",
      "易学习 0.308934869866\n",
      "有福 0.108549295069\n",
      "李达康 0.154467434933\n",
      "欧阳 0.0\n",
      "毛娅 0.0\n",
      "沙瑞金 0.154467434933\n",
      "没想到 0.108549295069\n",
      "没有 0.0\n",
      "浪费 0.0\n",
      "王大路 0.386168587332\n",
      "百姓 0.108549295069\n",
      "相助 0.108549295069\n",
      "竟然 0.108549295069\n",
      "股权 0.0\n",
      "胸怀 0.108549295069\n",
      "自己 0.0772337174664\n",
      "觉得 0.154467434933\n",
      "触动 0.108549295069\n",
      "话别 0.108549295069\n",
      "赔礼道歉 0.108549295069\n",
      "赞叹 0.108549295069\n",
      "踏实 0.0\n",
      "这些 0.0\n",
      "这件 0.108549295069\n",
      "连连 0.108549295069\n",
      "道口 0.108549295069\n",
      "金山 0.108549295069\n",
      "降职 0.108549295069\n",
      "风生水 0.108549295069\n",
      "-------第 1 段文本的词语tf-idf权重------\n",
      "一起 0.0\n",
      "万块 0.0\n",
      "三人 0.0\n",
      "三套 0.139891059658\n",
      "下海经商 0.0\n",
      "不想 0.139891059658\n",
      "不要 0.139891059658\n",
      "东挪西撮 0.0\n",
      "之后 0.139891059658\n",
      "事业有成 0.139891059658\n",
      "事对 0.0\n",
      "京州 0.279782119316\n",
      "他们 0.0995336411066\n",
      "以沫 0.0\n",
      "公司 0.139891059658\n",
      "分开 0.0\n",
      "别墅 0.279782119316\n",
      "前一晚 0.0\n",
      "县当 0.0\n",
      "县长 0.0\n",
      "可是 0.0995336411066\n",
      "名下 0.139891059658\n",
      "后来 0.0\n",
      "喝酒 0.0\n",
      "回忆起 0.0\n",
      "困难 0.0\n",
      "大家 0.0\n",
      "太大 0.139891059658\n",
      "她们 0.139891059658\n",
      "好像 0.139891059658\n",
      "家住 0.139891059658\n",
      "容易 0.0\n",
      "对不起 0.0\n",
      "帝豪园 0.139891059658\n",
      "开始 0.0\n",
      "很大 0.0\n",
      "房子 0.279782119316\n",
      "打听 0.139891059658\n",
      "时期 0.0\n",
      "易学习 0.0995336411066\n",
      "有福 0.0\n",
      "李达康 0.0995336411066\n",
      "欧阳 0.279782119316\n",
      "毛娅 0.419673178975\n",
      "沙瑞金 0.0995336411066\n",
      "没想到 0.0\n",
      "没有 0.139891059658\n",
      "浪费 0.139891059658\n",
      "王大路 0.29860092332\n",
      "百姓 0.0\n",
      "相助 0.0\n",
      "竟然 0.0\n",
      "股权 0.139891059658\n",
      "胸怀 0.0\n",
      "自己 0.0995336411066\n",
      "觉得 0.0995336411066\n",
      "触动 0.0\n",
      "话别 0.0\n",
      "赔礼道歉 0.0\n",
      "赞叹 0.0\n",
      "踏实 0.139891059658\n",
      "这些 0.139891059658\n",
      "这件 0.0\n",
      "连连 0.0\n",
      "道口 0.0\n",
      "金山 0.0\n",
      "降职 0.0\n",
      "风生水 0.0\n"
     ]
    }
   ],
   "source": [
    "wordlist = vector.get_feature_names()#获取词袋模型中的所有词  \n",
    "# tf-idf矩阵 元素a[i][j]表示j词在i类文本中的tf-idf权重\n",
    "weightlist = tfidf.toarray()  \n",
    "#打印每类文本的tf-idf词语权重，第一个for遍历所有文本，第二个for便利某一类文本下的词语权重\n",
    "for i in range(len(weightlist)):  \n",
    "    print \"-------第\",i,\"段文本的词语tf-idf权重------\"  \n",
    "    for j in range(len(wordlist)):  \n",
    "        print wordlist[j],weightlist[i][j]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 44)\t1\n",
      "  (0, 75)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 57)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 97)\t1\n",
      "  (0, 77)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 68)\t1\n",
      "  (0, 48)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 81)\t1\n",
      "  (0, 3)\t2\n",
      "  (0, 45)\t2\n",
      "  (0, 83)\t2\n",
      "  (0, 86)\t1\n",
      "  (0, 92)\t1\n",
      "  (0, 8)\t2\n",
      "  (0, 71)\t5\n",
      "  (0, 27)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 94)\t1\n",
      "  (0, 96)\t1\n",
      "  (0, 85)\t1\n",
      "  (0, 34)\t1\n",
      "  :\t:\n",
      "  (2, 60)\t1\n",
      "  (2, 46)\t1\n",
      "  (2, 52)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 53)\t2\n",
      "  (2, 74)\t1\n",
      "  (2, 64)\t1\n",
      "  (2, 17)\t1\n",
      "  (2, 89)\t1\n",
      "  (2, 76)\t1\n",
      "  (2, 42)\t2\n",
      "  (2, 33)\t1\n",
      "  (2, 28)\t1\n",
      "  (2, 72)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 49)\t1\n",
      "  (2, 35)\t1\n",
      "  (2, 50)\t2\n",
      "  (2, 21)\t1\n",
      "  (2, 62)\t2\n",
      "  (2, 7)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 66)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 81)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "corpus = [res1,res2,res3]\n",
    "cntVector = CountVectorizer(stop_words=stpwrdlst)\n",
    "cntTf = cntVector.fit_transform(corpus)\n",
    "print cntTf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=2, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "docres = lda.fit_transform(cntTf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.26769883  1.16102982  1.04461812  0.82518913  0.88206482  1.03114126\n",
      "   1.1885517   1.13996381  0.93194211  1.00688455  1.10354905  1.11630692\n",
      "   0.69928055  1.02435199  1.18093584  0.77370588  1.22974701  1.2431948\n",
      "   0.9286154   0.73965004  1.08269025  1.2223472   1.05647687  0.7751034\n",
      "   1.07969089  0.84507667  0.75950728  0.86078486  1.06789865  1.01899967\n",
      "   1.12893216  1.01505045  0.83309427  1.10521024  0.81853645  1.011645\n",
      "   0.76359532  0.90990692  0.94738     0.98640661  1.01621653  0.92993322\n",
      "   1.378293    0.97699963  0.79215505  0.96517309  1.16519283  0.85555997\n",
      "   0.97114453  1.11765233  1.37373229  0.97109894  1.15837182  1.45512821\n",
      "   1.14055357  1.14159898  0.8654311   0.95003605  0.98285046  0.82237984\n",
      "   1.27665706  1.05877617  1.38353298  1.15332271  1.17732506  1.29439329\n",
      "   1.15922322  0.91667578  0.8950295   1.10344976  0.94601797  1.43439026\n",
      "   1.0765302   0.91651801  1.08569577  0.92926558  1.16104387  0.80059138\n",
      "   1.14290502  1.03589518  0.81076569  1.3542147   1.12633107  1.15258967\n",
      "   0.86923617  0.8283271   0.79376796  0.84607238  0.95302084  1.28105551\n",
      "   0.89191116  0.9391752   0.80316179  1.02468113  0.95102785  0.89952071\n",
      "   0.80035877  0.92917501]\n",
      " [ 0.80628204  0.81469692  1.34342695  1.28066323  1.42620876  0.8842101\n",
      "   0.7860628   0.86783501  1.28049162  1.03224191  1.04392107  0.85173653\n",
      "   1.29455526  1.12041733  0.96502295  1.10392067  1.23918461  0.91224492\n",
      "   1.55098581  1.06912838  1.02578471  0.8563807   0.93331311  1.14520856\n",
      "   1.08720029  1.08950784  1.30125854  1.11601687  0.83124037  1.31431715\n",
      "   0.87558798  1.02854077  1.01873743  0.82883489  1.08067986  0.89608485\n",
      "   1.0392044   1.17738815  1.40753717  1.06829726  0.99890332  0.9953815\n",
      "   0.9555837   1.1033081   1.16024664  1.33063176  0.91549849  1.08542582\n",
      "   1.00409694  0.90968059  0.82458022  1.11248849  0.73151164  0.88051846\n",
      "   0.84155207  1.16447331  1.19269311  1.146285    2.11638152  1.1115924\n",
      "   0.72504866  1.7127765   0.81771361  1.292976    0.79013008  1.40962934\n",
      "   0.81899839  1.51606321  1.30203704  0.9180146   1.02517725  2.66645525\n",
      "   0.83572024  1.14556117  0.85584502  1.067851    0.77076768  1.02499129\n",
      "   0.91583485  0.99475649  1.11061671  1.35448141  0.83637158  1.52942333\n",
      "   1.11436122  1.11207849  1.14147815  1.05518863  0.92600769  0.84070595\n",
      "   0.96819235  1.1894113   1.1794093   0.78181593  0.99302282  1.1521424\n",
      "   1.20263811  1.08414725]]\n"
     ]
    }
   ],
   "source": [
    "print lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01054041  0.98945959]\n",
      " [ 0.0270532   0.9729468 ]\n",
      " [ 0.98245239  0.01754761]]\n"
     ]
    }
   ],
   "source": [
    "print docres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
